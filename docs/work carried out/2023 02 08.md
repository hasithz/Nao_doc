# Using only the GRU layers

## thinking process

I started from the beginning this time where I'll be going through the steps all over again but much faster. So this time I created 2 GRU cells with 32 hidden layers then feed it to the environment and saw that up to 4 players it was working partially without an sudden spikes here are there.

as for the input, A single observation was feed in to the network in the beginning and got a noisy plot. I assume that it fitted to a single value yet it can somehow move around the environment but still get a bad reward.

![updating the network by only using the input](https://github.com/hasithz/Nao_doc/blob/main/assets/images/GRU-2023-02-09.png?raw=true)


the next thing was input a whole sequence of data to the network, This gave me some promising result when considering all the other plots drawn so faw up to now. So in this position i experience that after adding the 4th player and running for some time the network explodes and goes it to complete randomness. 

![updating the network by the sequence but 2 GRU layers only](https://github.com/hasithz/Nao_doc/blob/main/assets/images/2GRU-2023-02-09.png?raw=true)

Here I saw that it can't learn because it didn't had enough parameters to learn the whole scenario. So the as for the next thing What i did was little bit hyper parameter tuning. Here I added num of layers in the GRU to 3. And as for the results the spikes have been minimized and the reward decay also has been reduced yet as for the overall reward process it goes down with a lower steep. 

![stacked GRU layers](https://github.com/hasithz/Nao_doc/blob/main/assets/images/2GRU3lyrs-2023-02-09.png?raw=true)
